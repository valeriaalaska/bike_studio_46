---
title: "Cyclistic_Documentation"
author: "Val de Oliveira"
date: "2022-07-30"
output: html_document
---

# Introduction
This analysis is based on the Divvy case study "'Sophisticated, Clear, and Polished’: Divvy and Data Visualization" written by Kevin Hartman (found here: https://artscience.blog/home/divvy-dataviz-case-study). The purpose of this script is to consolidate downloaded Divvy data into a single dataframe and then conduct simple analysis to help answer the key question: “In what ways do members and casual riders use Divvy bikes differently?”



**About Bike Studio 46**  
Bike Studio 46 is fictional bike-share company located in Chicago that features more than 5,800 bicycles and 600 docking stations. 

Besides offering traditional bikes, Cyclistic also offers reclining bikes, hand tricycles, and cargo bikes, making bike-share more inclusive to people with disabilities and riders who can’t use a standard two-wheeled bike. 

The majority of riders opt for traditional bikes; about 8% of riders use the assistive options. Cyclistic users are more likely to ride for leisure, but about 30% use them to commute to work each day.



**Purpose**  
The purpose of this case study is to conduct simple analysis to help answer the key question: “In what ways do members and casual riders use  bikes differently?”



**Our Data and Tools**
We will use "RStudio" for this project, since the data sets are very large.


# Analytical workflow
   - Setting up the environment by loading packages  
   - Importing the data  
   - Checking out the data  
   - Exploring the data  
   - Modelling the data  
   - Communicating the findings  


## Setting up the environment by loading packages  
Let's start our environment  by installing the following packages:  

   - **tidyverse** 
   - **lubridate**
   - **ggplot2**
   - **janitor**
   - **here**
   - **skimr**
   - **dplyr**

```{r}
install.packages("tidyverse")
install.packages("ludridale")
install.packages("ggplot2")
install.packages("janitor")
install.packages("here")
install.packages("skimr")
install.packages("dplyr")
```


Then we can load our packages:

```{r}
library(tidyverse)
library(lubridate)  
library(ggplot2)  
library(janitor)
library(here)
library(skimr)
library(dplyr)
```



## Importing the data
Now that our environment has been started, we can work on the data we will use for the project.

We will do a full year analysis, using the most recent data sets - from Q2_2019 to Q1_2020,  

Next, we can load the .csv files to  RStudio. 

```{r}
q2_2019 <- Divvy_Trips_2019_Q2
q3_2019 <- Divvy_Trips_2019_Q3
q4_2019 <- Divvy_Trips_2019_Q4
q1_2020 <- Divvy_Trips_2020_Q1

```



## Checking out the data
Now that the data is available in RStudio we can use use some functions to check the data and see what we have to work with.

Let's start using the "colnammes" function. This function lists all column names exiting in out data sets.


```{r}
colnames(q2_2019)

```

```{r}
colnames(q3_2019)


```

```{r}
colnames(q4_2019)
```

```{r}
colnames(q1_2020)
```



To explore our data a little more, let's run a few more functions:

 - nrow() -> this function will tell us how many rows there are in our data frame
 - dim()  -> the "dim" fucntion will tell us the dimensions of our data frame
 - str()  -> we will use the "str" function to list all columns and data types (numeric, character, etc)
 - head() / tail() -> then we will use the "head" and "tail" functions to see the first and last 6 rows of our data
 - summary()  -> and finally we will use the "summary" function for the statistical summary of out data. Mainly for numerics.



**dim()** 
```{r}
dim(q1_2020)
dim(q2_2019)
dim(q3_2019)
dim(q1_2020)
```


**str()**  
```{r}
str(q1_2020)
str(q2_2019)
str(q3_2019)
str(q1_2020)
```


**head()** 
```{r}
head(q1_2020)
head(q2_2019)
head(q3_2019)
head(q1_2020)
```


**summary()**  
```{r}
summary(q2_2019)
summary(q3_2019)
summary(q4_2019)
summary(q1_2020)
```


# Rename columns

After reviewing the data set structures, we realize that our column names are not consistent.

Let's fix that!

Let's match all data sets to the news data set, "q1_2020", since this will be the supposed going-forward table design for Divvy.


Renaming "q2_2019"
```{r}
(q2_2019 <- rename(q2_2019
                   ,ride_id = "01 - Rental Details Rental ID"
                   ,rideable_type = "01 - Rental Details Bike ID" 
                   ,started_at = "01 - Rental Details Local Start Time"  
                   ,ended_at = "01 - Rental Details Local End Time"  
                   ,start_station_name = "03 - Rental Start Station Name" 
                   ,start_station_id = "03 - Rental Start Station ID"
                   ,end_station_name = "02 - Rental End Station Name" 
                   ,end_station_id = "02 - Rental End Station ID"
                   ,member_casual = "User Type"))
```



Renaming "q3_2019"
```{r}
(q3_2019 <- rename(q3_2019
                   ,ride_id = trip_id
                   ,rideable_type = bikeid 
                   ,started_at = start_time  
                   ,ended_at = end_time  
                   ,start_station_name = from_station_name 
                   ,start_station_id = from_station_id 
                   ,end_station_name = to_station_name 
                   ,end_station_id = to_station_id 
                   ,member_casual = usertype))
```



Renaming "q4_2019"
```{r}
(q4_2019 <- rename(q4_2019
                   ,ride_id = trip_id
                   ,rideable_type = bikeid 
                   ,started_at = start_time  
                   ,ended_at = end_time  
                   ,start_station_name = from_station_name 
                   ,start_station_id = from_station_id 
                   ,end_station_name = to_station_name 
                   ,end_station_id = to_station_id 
                   ,member_casual = usertype))

```

Let's Inspect the dataframes now and look for incongruencies:
```{r}
str(q1_2020)
str(q4_2019)
str(q3_2019)
str(q2_2019)
```


We notice now that we need to Convert ride_id and rideable_type to character so that they can stack correctly:
```{r}

q4_2019 <-  mutate(q4_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
q3_2019 <-  mutate(q3_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
q2_2019 <-  mutate(q2_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
```



Now, let's Stack individual quarter's data frames into one big data frame and call it "all_trips"
```{r}
all_trips <- bind_rows(q2_2019, q3_2019, q4_2019, q1_2020)
```

Let's check to see if our new dataset looks good:
```{r}
colnames(all_trips)
```


Now, let's Remove some columns that we will not use in our analysis: lat, long, birthyear, and gender - these fields are also  not consistent in all quarters datasets.

```{r}
all_trips <- all_trips %>%  
  select(-c(start_lat, start_lng, end_lat, end_lng, birthyear, gender, "01 - Rental Details Duration In Seconds Uncapped", "05 - Member Details Member Birthday Year", "Member Gender", "tripduration"))


```


Let's check again out columns again...
```{r}
colnames(all_trips)
```

**Perfect!!!**

# Inspecting the new table that has been created
Let's check now our new dataset!
```{r}
colnames(all_trips)  #List of column names
nrow(all_trips)  #How many rows are in data frame?
dim(all_trips)  #Dimensions of the data frame?
head(all_trips)  #See the first 6 rows of data frame.  Also tail(all_trips)
str(all_trips)  #See list of columns and data types (numeric, character, etc)
summary(all_trips)  #Statistical summary of data. Mainly for numerics
```




## Exploring the data 
While exploring the data  we notice a few problems we need to work on:

1. In the "member_casual" column: there are two names for members ("member" and "Subscriber") and two names for casual riders ("Customer" and "casual"). We will need to consolidate that from four to two labels.


2. The data can only be aggregated at the ride-level, which is too granular. We will want to add some additional columns of data -- such as day, month, year -- that provide additional opportunities to aggregate the data.


3. We also want to add a calculated field for length of ride so we can have a trip duration column. 


4. There are also some rides where tripduration shows up as negative, including several hundred rides where Divvy took bikes out of circulation for Quality Control reasons. We will want to delete these rides.


Lets start replacing  "Subscriber" with "member" and "Customer" with "casual" in the "member_casual" column.

Before 2020, Divvy used different labels for these two types of riders ... we  want to make our dataframe consistent with their current nomenclature.

Let's begin by seeing how many observations fall under each usertype.

```{r}
table(all_trips$member_casual)

```


Now, let's reassign to the desired values (we will go with the current 2020 labels)
```{r}

all_trips <-  all_trips %>% 
  mutate(member_casual = recode(member_casual
                           ,"Subscriber" = "member"
                           ,"Customer" = "casual"))
```


Let's Check again to make sure the proper number of observations were reassigned.
```{r}
table(all_trips$member_casual)

```
Great!

Next, let's add columns to list  date, month, day, and year of each ride. This will allow us to aggregate ride data for each month, day, or year ... before completing these operations we could only aggregate at the ride level.


```{r}
all_trips$date <- as.Date(all_trips$started_at) #The default format is yyyy-mm-dd
all_trips$month <- format(as.Date(all_trips$date), "%m")
all_trips$day <- format(as.Date(all_trips$date), "%d")
all_trips$year <- format(as.Date(all_trips$date), "%Y")
all_trips$day_of_week <- format(as.Date(all_trips$date), "%A")

```


Now, let add a "ride_length" calculation (in seconds) to our data frame.
```{r}
all_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at)
```


Let's inspect the structure of the columns to make sure everything looks good.
```{r}
str(all_trips)
```


We notice now that in order to run calculations on the "ride_length" data, we nee to convert it from Factor to numeric. Let's do that now!

```{r}
is.factor(all_trips$ride_length)
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)

```


**Remove "bad" data**
As we notice before,  that the dataframe includes a few hundred entries when bikes were taken out of docks and checked for quality and the "ride_length" was negative. We need to delete this data.

Since data is being removed we will create a new version of the dataframe and call it "all_trips_v2".


```{r}
all_trips_v2 <- all_trips[!(all_trips$start_station_name == "HQ QR" | all_trips$ride_length<0),]
```


Now that our data is clean and ready we can conduct our analysis.


# Descriptive analysis on ride_length (all figures in seconds)

Let's use the "summary" function to check the data
```{r}
summary(all_trips_v2$ride_length)
```

Now we can compare members and casual users.
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = mean)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = median)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = max)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = min)

```

Let's also check the average ride time by each day for members vs casual users.
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```

We notice above that the days of the week are out of order. Let's fix that.

```{r}
all_trips_v2$day_of_week <- ordered(all_trips_v2$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

```


Let's  check again!
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```


Perfect!


Now, let's find out  the average ride time by each day for members vs casual users.
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```


Next, lets analyze ridership data by type and weekday.
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()							#calculates the number of rides and average duration 
  ,average_duration = mean(ride_length)) %>% 		# calculates the average duration
  arrange(member_casual, weekday)	

```

Great! 

Now we can visualize the number of rides by rider type.
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")

```

Let's also create a visualization for average duration
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```

Let's also check the most populat stations by summarizing the ride lengths.

```{r}
all_trips_v2 %>% #dataset used
  group_by(start_station_name) %>% # group by island column
  drop_na(ride_length) %>% # drop NA's
  summarize(sum_ride_length = sum(ride_length)) %>% 
   arrange(-sum_ride_length)#summarize 
 
```


Great! I think out analysis is complete! 


Now, lets create a csv file that we can use to visualize the data in Excel, Tableau, or any other presentation software.

First let's use "getwd" function to find our  directory path.
```{r}
getwd()
```


Now, let's save the "average ride length", then the "all trips" file!

```{r}
counts <- aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
write.csv(counts, file = 'C:\\Users\\valer\\OneDrive\\Desktop\\Courses\\PowerBI\\projects\\bike_case_study\\avg_ride_length.csv')
```


Let's now saves the clean file as an csv file in the designated directory.
```{r}
write.csv(all_trips_v2, file = 'C:\\Users\\valer\\OneDrive\\Desktop\\Courses\\PowerBI\\projects\\bike_case_study\\all_trips_v2.csv')
```


All done! Thanks for the "ride"! :)